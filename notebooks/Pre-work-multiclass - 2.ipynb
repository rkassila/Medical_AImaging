{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac6af856",
   "metadata": {},
   "source": [
    "<font size=\"12\">Exploring the datasets</font>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e13f623d",
   "metadata": {},
   "source": [
    "# Setting up"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9a4e2057",
   "metadata": {},
   "source": [
    "## Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "99394c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pathlib\n",
    "import keras\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.applications.vgg16 import VGG16, preprocess_input as preprocess_input_vgg16\n",
    "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input as preprocess_input_vgg19\n",
    "from tensorflow.keras.applications.resnet_v2 import ResNet50V2, preprocess_input as preprocess_input_resnet\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, MaxPool2D\n",
    "from tensorflow.keras import regularizers, layers\n",
    "from tensorflow.keras.optimizers.legacy import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.utils import shuffle\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b7b67fab",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe8861ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "url_normal = '../data/CT/Lung/normal/'\n",
    "\n",
    "url_airspace = '../data/CT/Lung/Airspace_opacity/'\n",
    "# url_bronch = '../data/CT/Lung/Bronchiectasis/'\n",
    "# url_inter = '../data/CT/Lung/interstitial_lung_disease/'\n",
    "# url_nodule = '../data/CT/Lung/Nodule/'\n",
    "# url_parenchyma = '../data/CT/Lung/Parenchyma_destruction/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ef85f3bf-4055-4faa-abb4-aa03f7ad2745",
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbda2fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_normal = [cv2.imread(file) for file in glob.glob(url_normal+\"*.png\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0bd99f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_airspace = [cv2.imread(file) for file in glob.glob(url_airspace+\"*.png\")][:limit]\n",
    "# images_bronch = [cv2.imread(file) for file in glob.glob(url_bronch+\"*.png\")][:limit]\n",
    "# images_inter = [cv2.imread(file) for file in glob.glob(url_inter+\"*.png\")][:limit]\n",
    "# images_nodule = [cv2.imread(file) for file in glob.glob(url_nodule+\"*.png\")][:limit]\n",
    "# images_parenchyma = [cv2.imread(file) for file in glob.glob(url_parenchyma+\"*.png\")][:limit]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3c333d0e-2189-4689-affc-8af65976c1e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a8163f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images_nodule = [cv2.imread(file) for file in glob.glob(url_nodule + \"*.png\")]\n",
    "labels_airspace = [2] * len(images_nodule)\n",
    "labels_bronch = [3] * len(images_nodule)\n",
    "labels_inter = [4] * len(images_nodule)\n",
    "labels_nodule = [1] * len(images_nodule)\n",
    "labels_parenchyma = [5] * len(images_nodule)\n",
    "\n",
    "#images_normal = [cv2.imread(file) for file in glob.glob(url_normal + \"*.png\")]\n",
    "labels_normal = [0] * len(images_normal)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ac21a135",
   "metadata": {},
   "source": [
    "## Checking data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7869df92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal_count = len(images_normal)\n",
    "normal_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "354c449e",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m img \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(\u001b[43mimages_nodule\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      2\u001b[0m imgplot \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39mimshow(img)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "img = np.asarray(images_nodule[0])\n",
    "imgplot = plt.imshow(img)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4a05d9c",
   "metadata": {},
   "source": [
    "# Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7577e229",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_model():\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(layers.Conv2D(256, (4,4), activation=\"relu\",\n",
    "                            input_shape=(224, 224, 3), padding = \"same\",kernel_regularizer=regularizers.L1L2(0.01,0.1)))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2), padding = \"same\"))\n",
    "    \n",
    "    model.add(layers.Conv2D(128, (3,3), activation=\"relu\", padding = \"same\"))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2), padding = \"same\"))\n",
    "    \n",
    "    model.add(layers.Conv2D(64, (3,3), activation=\"relu\", padding = \"same\"))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2), padding = \"same\"))\n",
    "    \n",
    "    model.add(layers.Conv2D(32, (2,2), activation=\"relu\"))\n",
    "    model.add(layers.MaxPool2D(pool_size=(2,2)))\n",
    "              \n",
    "    model.add(layers.Dropout(0.25)) \n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "\n",
    "    model.add(layers.Dense(6, activation='softmax'))\n",
    "    \n",
    "    ### Model compilation\n",
    "    model.compile(loss='sparse_categorical_crossentropy', \n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "       \n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7572d000-cf27-40c5-8ed5-2602e67f5cd8",
   "metadata": {},
   "source": [
    "##  VGG16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4922ab84-24f1-44ac-a473-399fb5330f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_vgg16_model():\n",
    "    # Load the pre-trained VGG16 model without the top (fully connected) layers\n",
    "    base_model = VGG16(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    # Freeze the layers of the pre-trained VGG16 model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Create a Sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add the pre-trained VGG16 model as the first layer\n",
    "    model.add(base_model)\n",
    "\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(500, activation='relu'))\n",
    "    model.add(Dropout(0.3))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "    # Model compilation\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21882352-a895-47f0-87b2-24e4ddb30483",
   "metadata": {},
   "source": [
    "## VGG19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "caa15784-b4ac-42a0-8473-e812320672e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_vgg19_model():\n",
    "    # Load the pre-trained VGG16 model without the top (fully connected) layers\n",
    "    base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "\n",
    "    # Freeze the layers of the pre-trained VGG19 model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Create a Sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "     # Add data augmentation layers\n",
    "    model.add(layers.RandomFlip(\"horizontal\"))\n",
    "    model.add(layers.RandomZoom(0.1))\n",
    "    model.add(layers.RandomTranslation(0.2, 0.2))\n",
    "    model.add(layers.RandomRotation(0.1))\n",
    "\n",
    "    # Add the pre-trained VGG16 model as the first layer\n",
    "    model.add(base_model)\n",
    "\n",
    "    # Add custom layers\n",
    "    # model.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=regularizers.L1L2(0.01, 0.1)))\n",
    "    # model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "    # Build the model\n",
    "    model.build((None, 224, 224, 3))\n",
    "\n",
    "    # Model compilation\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49355c1b-adb4-47b7-8756-2d8c2cc77bd0",
   "metadata": {},
   "source": [
    "## RestNet50V2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a2a6846-9cbb-49d2-9bd9-0e75c2d9ca5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_restnet50v2_model():\n",
    "    # Load the pre-trained VGG16 model without the top (fully connected) layers\n",
    "    base_model = ResNet50V2(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "    \n",
    "    # Freeze the layers of the pre-trained VGG19 model\n",
    "    for layer in base_model.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "    # Create a Sequential model\n",
    "    model = Sequential()\n",
    "\n",
    "    # Add the pre-trained VGG16 model as the first layer\n",
    "    model.add(base_model)\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    \n",
    "    model.add(Dense(6, activation='softmax'))\n",
    "\n",
    "    # Define data augmentation parameters\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        rotation_range=20,\n",
    "        width_shift_range=0.2,\n",
    "        height_shift_range=0.2,\n",
    "        shear_range=0.2,\n",
    "        zoom_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        fill_mode='nearest'\n",
    "    )\n",
    "    val_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "    # Model compilation\n",
    "    model.compile(loss='sparse_categorical_crossentropy',\n",
    "                  optimizer='adam',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    train_datagen.fit(X_train)\n",
    "\n",
    "    return model, train_datagen"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "3f029520",
   "metadata": {},
   "source": [
    "# Creating X and y for training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "57286d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.concatenate((images_airspace, images_bronch, images_inter, images_nodule, images_parenchyma, images_normal), axis=0)\n",
    "y = np.concatenate((labels_airspace, labels_bronch, labels_inter, labels_nodule, labels_parenchyma, labels_normal), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3d63bb51-7201-40e1-9948-d8e0d4ed398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = shuffle(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7c867393",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7da4d900-8820-4fff-818d-87f5dacc8bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size = 0.1, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57a09f04-7e4f-4933-9e30-6a336b832dc9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1271, 224, 224, 3)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f2989cb-04e2-4c86-89dc-91e7157035e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = preprocess_input(X_train) \n",
    "X_test = preprocess_input(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a71c0da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1271, 224, 224, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7a8a5afd-d355-413d-b65b-7ecc47b848ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1271,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6ea00e1",
   "metadata": {},
   "source": [
    "# Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "79352158",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# model = initialize_restnet50v2_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b95ff504-2ed5-49a3-b6b6-9071a362c00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming you have labels stored in a separate array y_train\n",
    "model, train_datagen = initialize_restnet50v2_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3a1a0503-2015-498e-af4e-2056edc9672e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " resnet50v2 (Functional)     (None, 7, 7, 2048)        23564800  \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 100352)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 602118    \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 24166918 (92.19 MB)\n",
      "Trainable params: 602118 (2.30 MB)\n",
      "Non-trainable params: 23564800 (89.89 MB)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "de136519-9250-4e10-bba1-3211ac34bc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=32)\n",
    "val_generator = train_datagen.flow(X_val, y_val, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "571500d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "40/40 [==============================] - 25s 605ms/step - loss: 2.6943 - accuracy: 0.3084 - val_loss: 17.8375 - val_accuracy: 0.1972\n",
      "Epoch 2/50\n",
      "40/40 [==============================] - 24s 601ms/step - loss: 1.8504 - accuracy: 0.3832 - val_loss: 23.9855 - val_accuracy: 0.1620\n",
      "Epoch 3/50\n",
      "40/40 [==============================] - 24s 604ms/step - loss: 1.8293 - accuracy: 0.4170 - val_loss: 38.6580 - val_accuracy: 0.1549\n",
      "Epoch 4/50\n",
      "40/40 [==============================] - 25s 621ms/step - loss: 2.0509 - accuracy: 0.4233 - val_loss: 45.7616 - val_accuracy: 0.1549\n",
      "Epoch 5/50\n",
      "33/40 [=======================>......] - ETA: 3s - loss: 1.9969 - accuracy: 0.4174"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 11\u001b[0m\n\u001b[1;32m      1\u001b[0m es \u001b[38;5;241m=\u001b[39m EarlyStopping(patience \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m, restore_best_weights\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# history = model.fit(X_train, y_train, \u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m#           epochs=50,\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m#           batch_size=32,\u001b[39;00m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m#           validation_split = 0.2,\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m#           callbacks=[es],\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m#           verbose=1)\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     14\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mes\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     16\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m50\u001b[39;49m\n\u001b[1;32m     17\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Medical_AImaging/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Medical_AImaging/lib/python3.10/site-packages/keras/src/engine/training.py:1742\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1734\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1736\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1739\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1740\u001b[0m ):\n\u001b[1;32m   1741\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1742\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1743\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1744\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Medical_AImaging/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Medical_AImaging/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:825\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    822\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 825\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    827\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    828\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Medical_AImaging/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:857\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    854\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    855\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    856\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 857\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    858\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_fn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    859\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    860\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    861\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Medical_AImaging/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py:148\u001b[0m, in \u001b[0;36mTracingCompiler.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    145\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n\u001b[1;32m    146\u001b[0m   (concrete_function,\n\u001b[1;32m    147\u001b[0m    filtered_flat_args) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m--> 148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfiltered_flat_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconcrete_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Medical_AImaging/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py:1349\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs)\u001b[0m\n\u001b[1;32m   1345\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1346\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1347\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1348\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1349\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_call_outputs(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1350\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1351\u001b[0m     args,\n\u001b[1;32m   1352\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1353\u001b[0m     executing_eagerly)\n\u001b[1;32m   1354\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Medical_AImaging/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:196\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    195\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 196\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    198\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    199\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    200\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    202\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28mlist\u001b[39m(args))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Medical_AImaging/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1457\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1455\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1456\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1457\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1458\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1459\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1460\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1461\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1462\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1463\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1464\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1466\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1467\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1471\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1472\u001b[0m   )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.6/envs/Medical_AImaging/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "es = EarlyStopping(patience = 5, restore_best_weights=True)\n",
    "\n",
    "# history = model.fit(X_train, y_train, \n",
    "#           epochs=50,\n",
    "#           batch_size=32,\n",
    "#           validation_split = 0.2,\n",
    "#           callbacks=[es],\n",
    "#           verbose=1)\n",
    "\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    callbacks=[es],\n",
    "    verbose=1,\n",
    "    epochs=50\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a5dfde77",
   "metadata": {},
   "source": [
    "# Testing the model and displaying results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b66ba8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_accuracy(history, title=None):\n",
    "    fig, ax = plt.subplots(1,2, figsize=(20,7))\n",
    "    \n",
    "    # --- LOSS --- \n",
    "    \n",
    "    ax[0].plot(history.history['loss'])\n",
    "    ax[0].plot(history.history['val_loss'])\n",
    "    ax[0].set_title('Model loss')\n",
    "    ax[0].set_ylabel('Loss')\n",
    "    ax[0].set_xlabel('Epoch')\n",
    "    ax[0].set_ylim((0,3))\n",
    "    ax[0].legend(['Train', 'Validation'], loc='best')\n",
    "    ax[0].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[0].grid(axis=\"y\",linewidth=0.5)\n",
    "    \n",
    "    # --- ACCURACY\n",
    "    \n",
    "    ax[1].plot(history.history['accuracy'])\n",
    "    ax[1].plot(history.history['val_accuracy'])\n",
    "    ax[1].set_title('Model Accuracy')\n",
    "    ax[1].set_ylabel('Accuracy')\n",
    "    ax[1].set_xlabel('Epoch')\n",
    "    ax[1].legend(['Train', 'Validation'], loc='best')\n",
    "    ax[1].set_ylim((0,1))\n",
    "    ax[1].grid(axis=\"x\",linewidth=0.5)\n",
    "    ax[1].grid(axis=\"y\",linewidth=0.5)\n",
    "    \n",
    "    if title:\n",
    "        fig.suptitle(title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4703552",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_loss_accuracy(history, title=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e641b2bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation = model.evaluate(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b3734ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'Model accuracy is {round(evaluation[1]*100,2)} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be1459b8-f0af-45ea-8844-ff535fe2a34e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9658d6ec-83c8-473b-89cd-75844c803d46",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
